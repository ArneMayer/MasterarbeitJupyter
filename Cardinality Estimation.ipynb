{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import errno\n",
    "from IPython.display import display, HTML\n",
    "import subprocess\n",
    "#import pdfkit as pdf\n",
    "\n",
    "#HTML(df.to_html())\n",
    "#display(df)\n",
    "\n",
    "hpi_red = '#b00639'\n",
    "hpi_blue = '#007a9e'\n",
    "\n",
    "def create_folder(filename):\n",
    "    if not os.path.exists(os.path.dirname(filename)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(filename))\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "def data_frame_to_pdf(df):\n",
    "    filename = 'out.tex'\n",
    "    pdffile = 'out.pdf'\n",
    "    outname = 'out.png'\n",
    "\n",
    "    template = r'''\\documentclass[preview]{{standalone}}\n",
    "    \\usepackage{{booktabs}}\n",
    "    \\begin{{document}}\n",
    "    {}\n",
    "    \\end{{document}}\n",
    "    '''\n",
    "\n",
    "    create_folder(filename)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(template.format(df.to_latex()))\n",
    "\n",
    "    subprocess.call(['pdflatex', filename])\n",
    "    subprocess.call(['convert', '-density', '300', pdffile, '-quality', '90', outname])\n",
    "    \n",
    "def data_frame_to_tex(df, filename):\n",
    "    create_folder(filename)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(df.to_latex())\n",
    "\n",
    "def get_column_names(benchmark): \n",
    "    file = 'results/' + benchmark + '_results.csv.json'\n",
    "    table_info = json.load(open(file,'r'))\n",
    "    #print(json.dumps(table_info, indent=2, sort_keys=False))\n",
    "    column_names = []\n",
    "    for column in table_info[\"columns\"]:\n",
    "        column_names.append(column[\"name\"])\n",
    "    return column_names\n",
    "\n",
    "def get_results(benchmark):\n",
    "    file = 'results/' + benchmark + '_results.csv'\n",
    "    return pd.read_csv(file, header=None, names=get_column_names(benchmark))\n",
    "\n",
    "def percent(x, pos):\n",
    "    'The two args are the value and tick position'\n",
    "    return ('%i' % (x * 100)) + \"%\"\n",
    "\n",
    "# Columns: sample_size, row_count, distinct_values, data, estimation_technique, error, occurrences \n",
    "def select(data, data_name, row_count, distinct_values, estimation_tec):\n",
    "    return data[(data.row_count == row_count) &\n",
    "                (data.distinct_values == distinct_values) &\n",
    "                (data.data_name == data_name) & \n",
    "                (data.estimation_technique == estimation_tec)]\n",
    "\n",
    "def get_mean_squared_error(errors, probabilities):\n",
    "    mse = 0.0\n",
    "    for i in range(0, len(errors)):\n",
    "        error = errors.iloc[i]\n",
    "        probability = probabilities.iloc[i]\n",
    "        mse += probability * error * error\n",
    "        \n",
    "    return mse\n",
    "\n",
    "def get_mean_error(errors, probabilities):\n",
    "    me = 0.0\n",
    "    for i in range(0, len(errors)):\n",
    "        error = errors.iloc[i]\n",
    "        probability = probabilities.iloc[i]\n",
    "        me += probability * abs(error)\n",
    "        #print(\"error: \" + str(error) + \", probability: \" + str(probability))\n",
    "        \n",
    "    return me\n",
    "\n",
    "def estimation_evaluation(data_name, row_count, distinct_values, estimation_tec):\n",
    "    #percent_formatter = FuncFormatter(percent)\n",
    "    #ax.yaxis.set_major_formatter(percent_formatter)\n",
    "    \n",
    "    #Prepare the data\n",
    "    data = get_results(\"estimation\")\n",
    "    selection = select(data, data_name, row_count, distinct_values, estimation_tec)\n",
    "    if len(selection) == 0:\n",
    "        return\n",
    "    sample_size = selection[\"sample_size\"].iloc[0]\n",
    "    errors = selection[\"error\"]\n",
    "    probabilities = selection[\"occurrences\"].apply(lambda x: x / sample_size)\n",
    "    biggest_error = max(max(errors), 0)\n",
    "    lowest_error = min(min(errors), 0)\n",
    "    x_data = range(lowest_error, biggest_error + 1)\n",
    "    y_data = np.zeros(biggest_error - lowest_error + 1)\n",
    "    for i in range(0, len(errors)):\n",
    "        y_data[errors.iloc[i] - lowest_error] = probabilities.iloc[i]     \n",
    "    #one_off_probability = 0\n",
    "    #if(len(y_data) > 1):\n",
    "    #    one_off_probability = y_data[1]\n",
    "    #correct_probability = y_data[0]\n",
    "    mean_error = get_mean_error(errors, probabilities)\n",
    "    mean_square_error = get_mean_squared_error(errors, probabilities)\n",
    "    #filter_size_bits = pow(2, quotient_size) * (2 + remainder_size)\n",
    "    #filter_size_bytes = filter_size_bits / 8\n",
    "    #bits_per_value = filter_size_bits / row_count\n",
    "    column_size = row_count * 2\n",
    "    \n",
    "    # Print some Information\n",
    "    print(\"Estimation Technique: \" + estimation_tec)\n",
    "    print(\"Sample Size: \" + str(sample_size))\n",
    "    #print(\"One off error probability: \" + str(one_off_probability))\n",
    "    print(\"Mean Error: \" + str(mean_error))\n",
    "    print(\"Mean Squared Error: \" + str(mean_square_error))\n",
    "    #print(\"Correct \" + str(correct_probability * 100) + \"%\" + \" of the time\")\n",
    "    #print(\"Filter Size [kB]: \" + str(filter_size_bytes / 1000))\n",
    "    #print(\"Bits per Value: \" + str(bits_per_value))\n",
    "    print(\"Column Size [kB](uint16_t): \"  + str(column_size / 1000))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Configure the plot\n",
    "    #title = \"Overcount probabilites\"\n",
    "    #subtitle = \"Value Count: \" + str(row_count) \\\n",
    "    #            + \", Distinct Values: \" + str(distinct_values) + \", Data: \" + data_name + '\\n'\\\n",
    "    #            + \"Quotient Size: \" + str(quotient_size) + \", Remainder Size: \" + str(remainder_size)\n",
    "    #fig, ax = plt.subplots()\n",
    "    #plt.title(title)# + '\\n' + subtitle)\n",
    "    ##.apply(lambda x: x * 100)\n",
    "    #plt.plot(x_data[1:100], np.array(y_data[1:100]) * 100, color=hpi_red, label=\"estimated counts\")\n",
    "    #plt.ylabel('Probability [%]')\n",
    "    #plt.xlabel('Overcount')\n",
    "    #ax.set_ylim(ymin=0)\n",
    "    #ax.set_xlim(xmin=1)\n",
    "    #ax.yaxis.grid()\n",
    "    #ax.xaxis.grid()\n",
    "    \n",
    "    # Save Output\n",
    "    #file_name = (title + '_' + subtitle).replace(\" \", \"_\").replace(\":\", \"_\").replace(\".\",\"_\") \\\n",
    "    #                                    .replace(\",\",\"_\").replace(\"\\n\",\"_\").replace(\"__\", \"_\")\n",
    "    #folder = \"plots/cardinality_estimation/\"\n",
    "    #create_folder(folder)\n",
    "    #plt.savefig(folder + '{}.pgf'.format(file_name))\n",
    "    #plt.savefig(folder + '{}.pdf'.format(file_name))\n",
    "    \n",
    "    #Render\n",
    "    #plt.show()\n",
    "\n",
    "def estimation_example(data_name, row_count, distinct_values, estimation_tec):\n",
    "    data = get_results(\"estimation_examples\")\n",
    "    selection = select(data, data_name, row_count, distinct_values, estimation_tec)\n",
    "    if len(selection) == 0:\n",
    "        return\n",
    "    \n",
    "    title = \"Estimated Counts Vs. Actual Counts\"\n",
    "    #subtitle = \"Value Count: \" + str(row_count) \\\n",
    "    #            + \", Distinct Values: \" + str(distinct_values) + \", Data: \" + data_distribution + '\\n' \\\n",
    "    #            + \"Quotient Size: \" + str(quotient_size) + \", Remainder Size: \" + str(remainder_size)\n",
    "    subtitle = \"Value Count: \" + str(row_count) \\\n",
    "                + \", Distinct Values: \" + str(distinct_values) + \", Data: \" + data_name + '\\n' \\\n",
    "                + estimation_tec\n",
    "            \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(title)# + '\\n' + subtitle)\n",
    "    plt.plot(selection[\"value\"], selection[\"estimated_count\"], color=hpi_red, label=\"Estimated Counts\")\n",
    "    plt.plot(selection[\"value\"], selection[\"actual_count\"], color=hpi_blue, label=\"Actual Counts\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylabel('Value Count')\n",
    "    plt.xlabel('Distinct Values')\n",
    "    ax.set_ylim(ymin=0)\n",
    "    ax.set_xlim(xmin=0)\n",
    "    ax.set_xlim(xmax=distinct_values)\n",
    "    \n",
    "    #file_name = (title + '_' + subtitle).replace(\" \", \"_\").replace(\":\", \"_\").replace(\".\",\"_\") \\\n",
    "    #                .replace(\",\",\"_\").replace(\"\\n\",\"_\").replace(\"__\", \"_\")\n",
    "    #create_folder(\"plots/cardinality_estimation/\")\n",
    "    #plt.savefig('plots/cardinality_estimation/{}.pgf'.format(file_name))\n",
    "    #plt.savefig('plots/cardinality_estimation/{}.pdf'.format(file_name))\n",
    "    plt.show()\n",
    "    \n",
    "def estimation_comparison_table(quotient_sizes, remainder_sizes, data_name, _count, distinct_values):\n",
    "    data = get_results(\"estimation\")\n",
    "    filter_information = []\n",
    "    for quotient_size in quotient_sizes:\n",
    "        for remainder_size in remainder_sizes:\n",
    "            estimation_tec = \"filter_\" + str(quotient_size) + \"_\" + str(remainder_size)\n",
    "            selection = select(data, data_name, row_count, distinct_values, estimation_tec)\n",
    "            if len(selection) > 0:\n",
    "                sample_size = selection[\"sample_size\"].iloc[0]\n",
    "                x_data = selection[\"error\"]\n",
    "                y_data = selection[\"occurrences\"].apply(lambda x: x / sample_size)\n",
    "                filter_size_bits = pow(2, quotient_size) * (2 + remainder_size)\n",
    "                filter_size_bytes = filter_size_bits / 8\n",
    "                bits_per_value = filter_size_bits / row_count\n",
    "                mean_error = get_mean_error(x_data, y_data)\n",
    "                mean_squared_error = get_mean_squared_error(x_data, y_data)\n",
    "                filter_information.append((estimation_tec, bits_per_value, mean_error, mean_squared_error))\n",
    "    \n",
    "    selection = select(data, data_name, row_count, distinct_values, \"postgres1_10\")\n",
    "    if len(selection) > 0:\n",
    "        sample_size = selection[\"sample_size\"].iloc[0]\n",
    "        x_data = selection[\"error\"]\n",
    "        y_data = selection[\"occurrences\"].apply(lambda x: x / sample_size)\n",
    "        mean_error = get_mean_error(x_data, y_data)\n",
    "        mean_squared_error = get_mean_squared_error(x_data, y_data)\n",
    "        filter_information.append((\"postgres1_10\", \"?\", mean_error, mean_squared_error))\n",
    "    \n",
    "    selection = select(data, data_name, row_count, distinct_values, \"postgres2_10\")\n",
    "    if len(selection) > 0:\n",
    "        sample_size = selection[\"sample_size\"].iloc[0]\n",
    "        x_data = selection[\"error\"]\n",
    "        y_data = selection[\"occurrences\"].apply(lambda x: x / sample_size)\n",
    "        mean_error = get_mean_error(x_data, y_data)\n",
    "        mean_squared_error = get_mean_squared_error(x_data, y_data)\n",
    "        filter_information.append((\"postgres2_10\", \"?\", mean_error, mean_squared_error))\n",
    "\n",
    "    columns = [\"Estimation Technique\", \"Bits per Value\", \"Mean Error\", \"Mean Squared Error\"]\n",
    "    df = pd.DataFrame(filter_information, columns=columns)\n",
    "    #display(df.sort_values(by=[\"Bits per Value\"]))\n",
    "    display(df)\n",
    "    file_name = data_name + str(distinct_values) + \"_filter_table\"\n",
    "    data_frame_to_tex(df, 'plots/cardinality_estimation/{}.tex'.format(file_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimation Technique</th>\n",
       "      <th>Bits per Value</th>\n",
       "      <th>Mean Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>filter_14_4</td>\n",
       "      <td>0.98304</td>\n",
       "      <td>0.377907</td>\n",
       "      <td>21.585953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>filter_14_8</td>\n",
       "      <td>1.6384</td>\n",
       "      <td>0.020290</td>\n",
       "      <td>1.115670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filter_14_16</td>\n",
       "      <td>2.94912</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.008387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>postgres1_10</td>\n",
       "      <td>?</td>\n",
       "      <td>6.331000</td>\n",
       "      <td>66.339000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>postgres2_10</td>\n",
       "      <td>?</td>\n",
       "      <td>24.709000</td>\n",
       "      <td>768.159000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Estimation Technique Bits per Value  Mean Error  Mean Squared Error\n",
       "0          filter_14_4        0.98304    0.377907           21.585953\n",
       "1          filter_14_8         1.6384    0.020290            1.115670\n",
       "2         filter_14_16        2.94912    0.000180            0.008387\n",
       "3         postgres1_10              ?    6.331000           66.339000\n",
       "4         postgres2_10              ?   24.709000          768.159000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "value_count = 100000\n",
    "distinct_values = 3000\n",
    "data_name = \"normal\"\n",
    "remainder_sizes = [2, 4, 8, 16]\n",
    "quotient_sizes = [12, 13, 14]\n",
    "estimation_comparison_table(quotient_sizes, remainder_sizes, data_name, row_count, distinct_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Technique: filter_14_4\n",
      "Sample Size: 300000\n",
      "Mean Error: 0.372413333333\n",
      "Mean Squared Error: 94.1491666667\n",
      "Column Size [kB](uint16_t): 200.0\n",
      "\n",
      "Estimation Technique: filter_14_8\n",
      "Sample Size: 300000\n",
      "Mean Error: 0.0327433333333\n",
      "Mean Squared Error: 10.0195966667\n",
      "Column Size [kB](uint16_t): 200.0\n",
      "\n",
      "Estimation Technique: filter_14_16\n",
      "Sample Size: 300000\n",
      "Mean Error: 0.0\n",
      "Mean Squared Error: 0.0\n",
      "Column Size [kB](uint16_t): 200.0\n",
      "\n",
      "Estimation Technique: postgres1_10\n",
      "Sample Size: 3000\n",
      "Mean Error: 4.59066666667\n",
      "Mean Squared Error: 247.644666667\n",
      "Column Size [kB](uint16_t): 200.0\n",
      "\n",
      "Estimation Technique: postgres2_10\n",
      "Sample Size: 3000\n",
      "Mean Error: 28.3566666667\n",
      "Mean Squared Error: 4099.66066667\n",
      "Column Size [kB](uint16_t): 200.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remainder_sizes = [2, 4, 8, 16]\n",
    "quotient_sizes = [12, 13, 14]\n",
    "data_name = \"zipf\"\n",
    "row_count = 100000\n",
    "distinct_values = 3000\n",
    "\n",
    "for quotient_size in quotient_sizes:\n",
    "    for remainder_size in remainder_sizes:\n",
    "        estimation_tec = \"filter_\" + str(quotient_size) + \"_\" + str(remainder_size)\n",
    "        #estimation_example(data_name, row_count, distinct_values, estimation_tec)\n",
    "        estimation_evaluation(data_name, row_count, distinct_values, estimation_tec)\n",
    "        \n",
    "#estimation_example(data_name, row_count, distinct_values, \"postgres1_10\")    \n",
    "estimation_evaluation(data_name, row_count, distinct_values, \"postgres1_10\")\n",
    "\n",
    "#estimation_example(data_name, row_count, distinct_values, \"postgres2_10\")\n",
    "estimation_evaluation(data_name, row_count, distinct_values, \"postgres2_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Technique: filter_14_4\n",
      "Sample Size: 300000\n",
      "Mean Error: 0.37972\n",
      "Mean Squared Error: 12.68322\n",
      "Column Size [kB](uint16_t): 200.0\n",
      "\n",
      "Estimation Technique: filter_14_8\n",
      "Sample Size: 300000\n",
      "Mean Error: 0.022\n",
      "Mean Squared Error: 0.726\n",
      "Column Size [kB](uint16_t): 200.0\n",
      "\n",
      "Estimation Technique: filter_14_16\n",
      "Sample Size: 300000\n",
      "Mean Error: 0.0\n",
      "Mean Squared Error: 0.0\n",
      "Column Size [kB](uint16_t): 200.0\n",
      "\n",
      "Estimation Technique: postgres1_10\n",
      "Sample Size: 3000\n",
      "Mean Error: 0.0\n",
      "Mean Squared Error: 0.0\n",
      "Column Size [kB](uint16_t): 200.0\n",
      "\n",
      "Estimation Technique: postgres2_10\n",
      "Sample Size: 3000\n",
      "Mean Error: 0.0\n",
      "Mean Squared Error: 0.0\n",
      "Column Size [kB](uint16_t): 200.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = \"normal\"\n",
    "distinct_values = 3000\n",
    "row_count = 100000\n",
    "\n",
    "#evaluate(14, 4, data, distinct_values)\n",
    "misestimation_evaluation(row_count, distinct_values, data_name, \"filter_14_4\")\n",
    "#evaluate(14, 8, data, distinct_values)\n",
    "misestimation_evaluation(row_count, distinct_values, data_name, \"filter_14_8\")\n",
    "#evaluate(14, 16, data, distinct_values)\n",
    "misestimation_evaluation(row_count, distinct_values, data_name, \"filter_14_16\")\n",
    "misestimation_evaluation(row_count, distinct_values, data_name, \"postgres1_10\")\n",
    "misestimation_evaluation(row_count, distinct_values, data_name, \"postgres2_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
